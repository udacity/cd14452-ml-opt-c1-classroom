{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ebd7af3",
   "metadata": {},
   "source": [
    "# Import Required Libraries and Set Up Configuration\n",
    "This cell:\n",
    "- Imports standard libraries for file handling, math operations, and context management.\n",
    "- Imports PyTorch for deep learning operations.\n",
    "- Imports Hugging Face Transformers for tokenization and model loading.\n",
    "- Imports Optimum Quanto for post-training quantization.\n",
    "- Sets up the model ID, device configuration, and random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009e9ac1-df12-439f-a19c-108b6629eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time, math, gc, tempfile, json, contextlib\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Optimum (Quanto) for post-training quantization (static, weight-only int8)\n",
    "from optimum.quanto import quantize, freeze, qint8\n",
    "\n",
    "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED     = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbc05f-e232-48cc-888d-0aafdae30dac",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "This section contains utility functions:\n",
    "- To measure the size of a directory in megabytes.\n",
    "- To monitor GPU memory usage during execution.\n",
    "- To define a data structure for storing generation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19312df6-4362-46f7-bd40-4f83f3d19cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_size_mb(path: str) -> float:\n",
    "    total = 0\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            total += os.path.getsize(os.path.join(root, f))\n",
    "    return total / (1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc2ecd9-c2e2-4e7f-8b30-d2b98bef2b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def torch_cuda_monitor():\n",
    "    \"\"\"Context manager to measure peak GPU memory in MB.\"\"\"\n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.synchronize()\n",
    "        start_alloc = torch.cuda.memory_allocated()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            torch.cuda.synchronize()\n",
    "            peak = torch.cuda.max_memory_allocated()\n",
    "            torch.cuda.empty_cache()\n",
    "            # return values indirectly by storing on the function object\n",
    "            torch_cuda_monitor.peak_mb = peak / (1024**2)\n",
    "            torch_cuda_monitor.start_mb = start_alloc / (1024**2)\n",
    "    else:\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            torch_cuda_monitor.peak_mb = 0.0\n",
    "            torch_cuda_monitor.start_mb = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8dde08e-9dd8-4d28-abed-3c79c7270735",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenMetrics:\n",
    "    latency_s: float\n",
    "    tokens_per_sec: float\n",
    "    peak_gpu_mem_mb: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c86ee",
   "metadata": {},
   "source": [
    "# Measure Text Generation Performance\n",
    "This function:\n",
    "- Measures the latency, throughput, and peak GPU memory usage during text generation.\n",
    "- Performs a warmup run to stabilize performance.\n",
    "- Uses multiple runs to calculate average metrics for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1c4a50-a21c-431e-8e82-41ce16df3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_generate(model, tokenizer, prompt: str, max_new_tokens=64, runs=3) -> GenMetrics:\n",
    "    \"\"\"Measure latency, throughput, and peak GPU memory for text generation.\"\"\"\n",
    "    model.eval()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Warmup\n",
    "    with torch.inference_mode():\n",
    "        _ = model.generate(**inputs, max_new_tokens=8, do_sample=False, use_cache=True)\n",
    "\n",
    "    latencies, tps = [], []\n",
    "    with torch_cuda_monitor():\n",
    "        for _ in range(runs):\n",
    "            if DEVICE == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            t0 = time.perf_counter()\n",
    "            with torch.inference_mode():\n",
    "                out = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False, use_cache=True)\n",
    "            if DEVICE == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            t1 = time.perf_counter()\n",
    "\n",
    "            gen_len = out.shape[1] - input_len\n",
    "            lat = t1 - t0\n",
    "            latencies.append(lat)\n",
    "            tps.append(gen_len / lat if lat > 0 else float(\"nan\"))\n",
    "\n",
    "    return GenMetrics(\n",
    "        latency_s=sum(latencies)/len(latencies),\n",
    "        tokens_per_sec=sum(tps)/len(tps),\n",
    "        peak_gpu_mem_mb=getattr(torch_cuda_monitor, \"peak_mb\", 0.0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee795b5",
   "metadata": {},
   "source": [
    "# Compute Perplexity\n",
    "This function:\n",
    "- Computes the perplexity of the model using a small built-in evaluation text.\n",
    "- Evaluates how well the model predicts text by calculating the negative log-likelihood.\n",
    "- Compares FP32 and INT8 models to observe the impact of quantization on perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5021512a-31a3-4838-a7bd-49b17bda4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_perplexity(model, tokenizer, seq_len=128) -> float:\n",
    "    \"\"\"\n",
    "    Self-contained perplexity estimate using a small built-in eval text.\n",
    "    Keeps evaluation light but still allows FP32 vs INT8 comparison.\n",
    "    \"\"\"\n",
    "    eval_text = (\n",
    "        \"Quantization reduces the precision of neural network weights and activations. \"\n",
    "        \"This process shrinks model size, lowers memory use, and can speed up inference. \"\n",
    "        \"The tradeoff is a small drop in accuracy. \"\n",
    "        \"Perplexity measures how well a language model predicts text: \"\n",
    "        \"a lower perplexity means the model is more confident in its predictions. \"\n",
    "        \"Large language models like LLaMA or TinyLlama are evaluated on benchmarks such as WikiText, \"\n",
    "        \"where perplexity is calculated over thousands of tokens. \"\n",
    "        \"In practice, we only need a small text sample to compare relative changes. \"\n",
    "        \"By quantizing a model to 8-bit, we can observe whether perplexity increases significantly. \"\n",
    "        \"If the rise is modest while speed and memory improve, quantization is usually a good trade-off. \"\n",
    "        \"This evaluation text is deliberately extended to ensure enough tokens for testing.\"\n",
    "    )\n",
    "\n",
    "    enc = tokenizer(eval_text, return_tensors=\"pt\")\n",
    "    input_ids = enc[\"input_ids\"][0]\n",
    "\n",
    "    usable = (len(input_ids) // seq_len) * seq_len\n",
    "    input_ids = input_ids[:usable + 1]\n",
    "    if len(input_ids) <= seq_len:\n",
    "        raise ValueError(\"Not enough tokens for perplexity calculation. Try reducing seq_len.\")\n",
    "\n",
    "    nll_sum, tok_count = 0.0, 0\n",
    "    model.eval()\n",
    "\n",
    "    for start in range(0, len(input_ids) - 1 - seq_len, seq_len):\n",
    "        chunk = input_ids[start:start+seq_len+1]\n",
    "        inp = chunk[:-1].unsqueeze(0).to(DEVICE)\n",
    "        labels = chunk[1:].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        out = model(input_ids=inp, labels=labels)\n",
    "        nll_sum += float(out.loss) * labels.numel()\n",
    "        tok_count += labels.numel()\n",
    "\n",
    "    return math.exp(nll_sum / max(1, tok_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b590ab5",
   "metadata": {},
   "source": [
    "# Save Model and Measure Size\n",
    "This function:\n",
    "- Saves the model and tokenizer to a specified directory.\n",
    "- Measures the size of the saved directory in megabytes.\n",
    "- Ensures the directory is cleaned before saving to avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843a4a98-1347-4eee-8320-6565e3fbf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_size(model, tokenizer, out_dir: str) -> float:\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    tokenizer.save_pretrained(out_dir)\n",
    "    model.save_pretrained(out_dir, safe_serialization=True)\n",
    "    return dir_size_mb(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c858e",
   "metadata": {},
   "source": [
    "# Print Metrics Row\n",
    "This function:\n",
    "- Prints a formatted row of metrics for a model.\n",
    "- Includes metrics such as size, latency, throughput, peak GPU memory, and perplexity.\n",
    "- Provides a clear and concise summary of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1bbdbe-a2a6-4376-b275-1785547eab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(title, size_mb, lat_s, tps, gpu_mb, ppl):\n",
    "    print(\n",
    "        f\"{title:18s} | Size: {size_mb:8.1f} MB | Latency: {lat_s:7.3f} s | \"\n",
    "        f\"Throughput: {tps:7.2f} tok/s | Peak VRAM: {gpu_mb:7.1f} MB | PPL: {ppl:7.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59212f",
   "metadata": {},
   "source": [
    "# Load Tokenizer\n",
    "This cell:\n",
    "- Loads the tokenizer for the specified model.\n",
    "- Ensures that padding tokens are set to make generation and perplexity calculations robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7748cbea-a298-4251-90e0-2de38d68dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "# Some chat models have no pad token; make generation/perplexity robust:\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1471785",
   "metadata": {},
   "source": [
    "# Baseline FP32 Model Evaluation\n",
    "This cell:\n",
    "- Loads the baseline FP32 model.\n",
    "- Measures the model's size, latency, throughput, and perplexity.\n",
    "- Prints the evaluation metrics for the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dadcb532-6185-4a5a-a52d-9cf0aaf8e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Baseline FP32 ==\n",
      "FP32 (baseline)    | Size:   4198.6 MB | Latency:   2.702 s | Throughput:   47.39 tok/s | Peak VRAM:  4218.8 MB | PPL:    1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n== Baseline FP32 ==\")\n",
    "baseline_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "baseline_model.to(DEVICE)\n",
    "\n",
    "baseline_size_mb = save_and_size(baseline_model, tokenizer, out_dir=\"tinyllama_fp32\")\n",
    "baseline_gen = measure_generate(\n",
    "    baseline_model,\n",
    "    tokenizer,\n",
    "    prompt=\"Explain quantization in one paragraph for ML engineers.\",\n",
    "    max_new_tokens=128,\n",
    "    runs=3,\n",
    ")\n",
    "baseline_ppl = compute_perplexity(baseline_model, tokenizer, seq_len=128)\n",
    "\n",
    "print_row(\"FP32 (baseline)\", baseline_size_mb, baseline_gen.latency_s, baseline_gen.tokens_per_sec,\n",
    "          baseline_gen.peak_gpu_mem_mb, baseline_ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5902e",
   "metadata": {},
   "source": [
    "# Quantized INT8 Model Evaluation\n",
    "This cell:\n",
    "- Performs post-training quantization (PTQ) on the model using Optimum Quanto.\n",
    "- Measures the quantized model's size, latency, throughput, and perplexity.\n",
    "- Prints the evaluation metrics for the quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cab1fb-62a2-41bd-a3f2-9dd89ee245fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== PTQ INT8 (Optimum-Quanto, weight-only) ==\n",
      "INT8 (Quanto)      | Size:   1240.8 MB | Latency:   6.624 s | Throughput:   19.33 tok/s | Peak VRAM:  5771.4 MB | PPL:    1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n== PTQ INT8 (Optimum-Quanto, weight-only) ==\")\n",
    "q_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# Static PTQ (weight-only): no calibration set required.\n",
    "# This converts Linear weights to int8-packed format and wires quant/dequant where needed.\n",
    "quantize(q_model, weights=qint8)\n",
    "freeze(q_model)               # finalize quantization graphs / params\n",
    "q_model.to(DEVICE)\n",
    "\n",
    "q_size_mb = save_and_size(q_model, tokenizer, out_dir=\"tinyllama_int8_quanto\")\n",
    "\n",
    "q_gen = measure_generate(\n",
    "    q_model,\n",
    "    tokenizer,\n",
    "    prompt=\"Explain quantization in one paragraph for ML engineers.\",\n",
    "    max_new_tokens=128,\n",
    "    runs=3,\n",
    ")\n",
    "q_ppl = compute_perplexity(q_model, tokenizer, seq_len=128)\n",
    "\n",
    "print_row(\"INT8 (Quanto)\", q_size_mb, q_gen.latency_s, q_gen.tokens_per_sec, q_gen.peak_gpu_mem_mb, q_ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56370cdd",
   "metadata": {},
   "source": [
    "# Save Summary as JSON\n",
    "This cell:\n",
    "- Saves the evaluation metrics for both the FP32 and INT8 models into a JSON file.\n",
    "- Provides a structured summary of the results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0af01-42ac-42f6-a745-69f5669f918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved summary -> ptq_tinyllama_summary.json\n"
     ]
    }
   ],
   "source": [
    "# --- 5) Summary JSON (optional) ----------------------------------------------\n",
    "summary = {\n",
    "    \"device\": DEVICE,\n",
    "    \"model\": MODEL_ID,\n",
    "    \"seed\": SEED,\n",
    "    \"baseline_fp32\": {\n",
    "        \"size_mb\": baseline_size_mb,\n",
    "        \"latency_s\": baseline_gen.latency_s,\n",
    "        \"tokens_per_sec\": baseline_gen.tokens_per_sec,\n",
    "        \"peak_gpu_mem_mb\": baseline_gen.peak_gpu_mem_mb,\n",
    "        \"perplexity\": baseline_ppl,\n",
    "    },\n",
    "    \"int8_quanto\": {\n",
    "        \"size_mb\": q_size_mb,\n",
    "        \"latency_s\": q_gen.latency_s,\n",
    "        \"tokens_per_sec\": q_gen.tokens_per_sec,\n",
    "        \"peak_gpu_mem_mb\": q_gen.peak_gpu_mem_mb,\n",
    "        \"perplexity\": q_ppl,\n",
    "    },\n",
    "}\n",
    "with open(\"ptq_tinyllama_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved summary -> ptq_tinyllama_summary.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4493789-c6de-4184-a1a0-d71950f6d97b",
   "metadata": {},
   "source": [
    "# Part 2: CPU Quantization and Evaluation\n",
    "This section:\n",
    "- Demonstrates dynamic quantization on CPU using PyTorch.\n",
    "- Evaluates the model's performance in terms of latency and throughput.\n",
    "- Compares the FP32 and INT8 dynamic quantized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c0ced22-a4a4-4678-a05a-9894682ea773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CPU FP32 Baseline ==\n",
      "FP32 (CPU) | Latency 0.787s | Throughput 1.28 tok/s\n",
      "\n",
      "== CPU INT8 (dynamic) ==\n",
      "INT8 dyn (CPU) | Latency 0.171s | Throughput 7.39 tok/s\n",
      "\n",
      "== Summary ==\n",
      "CPU FP32 latency: 0.787s | CPU INT8 latency: 0.171s | Speedup: 4.59x\n",
      "CPU FP32 tput:   1.28 tok/s | CPU INT8 tput:   7.39 tok/s\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.ao.quantization import quantize_dynamic\n",
    "\n",
    "# -----------------------------\n",
    "# Config (CPU-only demo)\n",
    "# -----------------------------\n",
    "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # swap to \"sshleifer/tiny-gpt2\" if CPU is tight\n",
    "DEVICE = \"cpu\"\n",
    "MAX_NEW_TOKENS = 128\n",
    "RUNS = 3\n",
    "PROMPT = \"Quantization test: explain why int8 dynamic quantization can be faster on CPU.\"\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_num_threads(max(1, os.cpu_count() or 1))  # let PyTorch use available cores\n",
    "\n",
    "def measure_generate(model, tokenizer, prompt=PROMPT, max_new_tokens=MAX_NEW_TOKENS, runs=RUNS):\n",
    "    model.eval()\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    enc = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    # Warmup\n",
    "    with torch.inference_mode():\n",
    "        _ = model.generate(**enc, max_new_tokens=8, use_cache=True)\n",
    "\n",
    "    latencies, throughputs = [], []\n",
    "    for _ in range(runs):\n",
    "        t0 = time.perf_counter()\n",
    "        with torch.inference_mode():\n",
    "            out = model.generate(**enc, max_new_tokens=max_new_tokens, use_cache=True)\n",
    "        t1 = time.perf_counter()\n",
    "        gen_len = out.shape[1] - enc[\"input_ids\"].shape[1]\n",
    "        lat = t1 - t0\n",
    "        latencies.append(lat)\n",
    "        throughputs.append(gen_len / lat)\n",
    "\n",
    "    return sum(latencies)/len(latencies), sum(throughputs)/len(throughputs)\n",
    "\n",
    "# -----------------------------\n",
    "# Tokenizer (shared)\n",
    "# -----------------------------\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token_id = tok.eos_token_id\n",
    "\n",
    "# -----------------------------\n",
    "# Baseline: FP32 on CPU\n",
    "# -----------------------------\n",
    "print(\"== CPU FP32 Baseline ==\")\n",
    "model_fp32 = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=torch.float32).to(DEVICE).eval()\n",
    "model_fp32.config.use_cache = True\n",
    "\n",
    "lat_fp32, tps_fp32 = measure_generate(model_fp32, tok)\n",
    "print(f\"FP32 (CPU) | Latency {lat_fp32:.3f}s | Throughput {tps_fp32:.2f} tok/s\")\n",
    "\n",
    "# -----------------------------\n",
    "# Quantized: INT8 dynamic (CPU)\n",
    "# -----------------------------\n",
    "print(\"\\n== CPU INT8 (dynamic) ==\")\n",
    "# Quantize only Linear layers to int8 (native PyTorch). This is weight-only int8 + dynamic activation quant.\n",
    "model_int8 = quantize_dynamic(\n",
    "    model_fp32.cpu(),\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ").eval()\n",
    "\n",
    "lat_int8, tps_int8 = measure_generate(model_int8, tok)\n",
    "print(f\"INT8 dyn (CPU) | Latency {lat_int8:.3f}s | Throughput {tps_int8:.2f} tok/s\")\n",
    "\n",
    "# -----------------------------\n",
    "# Summary\n",
    "# -----------------------------\n",
    "speedup = lat_fp32 / lat_int8 if lat_int8 > 0 else float(\"inf\")\n",
    "print(\"\\n== Summary ==\")\n",
    "print(f\"CPU FP32 latency: {lat_fp32:.3f}s | CPU INT8 latency: {lat_int8:.3f}s | Speedup: {speedup:.2f}x\")\n",
    "print(f\"CPU FP32 tput:   {tps_fp32:.2f} tok/s | CPU INT8 tput:   {tps_int8:.2f} tok/s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366feef7-53fa-42c5-bf87-dbd46d4d0117",
   "metadata": {},
   "source": [
    "# [EX-1] Calibration Set + Static PTQ (Optimum)\n",
    "This section:\n",
    "- Implements static PTQ using a calibration dataset.\n",
    "- Prepares a set of calibration texts and builds a DataLoader for calibration.\n",
    "- Uses Optimum-Intel to perform static quantization and save the quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bf8bf-d745-4882-8439-0edd2c233b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c14c169-0d90-4051-88f5-7abae44f58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_calibration_texts():\n",
    "    \"\"\"\n",
    "    Return ~15–30 short, varied sentences for calibration.\n",
    "    Mixed styles: facts, questions, lists, numbers, dates, code-ish, etc.\n",
    "    Each is short to keep tokenization light.\n",
    "    \"\"\"\n",
    "    CALIB_TEXTS = [\n",
    "        \"Neural networks approximate functions by composing linear and nonlinear transformations.\",\n",
    "        \"How many parameters are in a small language model with 100 million weights?\",\n",
    "        \"Shopping list: apples, rice, coffee beans, and two bottles of water.\",\n",
    "        \"Python snippet: for i in range(3): print(i) # demo\",\n",
    "        \"In 2024, researchers explored post-training quantization to reduce memory while preserving accuracy.\",\n",
    "        \"Temperature today is 18°C with light winds from the west.\",\n",
    "        \"Please summarize the article in one concise paragraph.\",\n",
    "        \"Quantization maps FP32 weights to lower-precision formats like INT8.\",\n",
    "        \"Q: What is perplexity? A: A measure of how confidently a model predicts tokens.\",\n",
    "        \"TODO: refactor the data loader and add unit tests for edge cases.\",\n",
    "        \"Benchmark setup: batch size 1, max new tokens 64, three runs, median latency.\",\n",
    "        \"The matrix A has eigenvalues [1.2, 0.7, 0.1] indicating contraction.\",\n",
    "        \"Version 1.3.7 fixed a regression in the tokenizer’s handling of special tokens.\",\n",
    "        \"A short story: The rover paused, scanned the ridge, and rolled forward.\",\n",
    "        \"CPU vs GPU: choose based on throughput, latency, and cost targets.\",\n",
    "        \"Top-3 tasks: clean data, train baseline, and ship a minimal dashboard.\",\n",
    "        \"Security note: never log API keys or tokens to stdout.\",\n",
    "        \"Quantization-aware training simulates low precision during training to reduce accuracy loss.\",\n",
    "        \"Meeting at 10:30 on Friday to review metrics and decide next steps.\",\n",
    "        \"Answer in bullet points: speed, memory, energy, and portability.\",\n",
    "        \"The dataset contains 120,000 rows and 17 columns, mostly numeric features.\",\n",
    "        \"Question: Why does dynamic quantization help Linear layers on CPU?\",\n",
    "        \"The compiler emitted warnings about deprecated CUDA kernels.\",\n",
    "        \"A recipe: preheat oven to 180°C, mix ingredients, bake for 25 minutes.\",\n",
    "        \"Inference logs include time stamps, token counts, and cache-hit ratios.\",\n",
    "        \"Note: padding tokens should not affect loss computation or attention.\",\n",
    "        \"Checklist: reproducibility, seeding, device placement, and data order.\",\n",
    "        \"The model failed to converge with LR=1e-1; try 3e-4 instead.\",\n",
    "        \"On-device AI can reduce latency and preserve privacy.\",\n",
    "        \"Final reminder: document your experiments and commit configs.\"\n",
    "    ]\n",
    "    return CALIB_TEXTS\n",
    "\n",
    "\n",
    "def make_calib_dataloader(tokenizer, texts, batch_size=4, max_length=256):\n",
    "    \"\"\"\n",
    "    Build a torch DataLoader yielding dicts with 'input_ids' and 'attention_mask'.\n",
    "    - Tokenize with truncation + max_length\n",
    "    - Pad with a simple collator (pad_token_id = tokenizer.pad_token_id or eos as fallback)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    class _CalibDS(Dataset):\n",
    "        def __init__(self, texts_):\n",
    "            self.texts = texts_\n",
    "        def __len__(self): \n",
    "            return len(self.texts)\n",
    "        def __getitem__(self, idx):\n",
    "            enc = tokenizer(\n",
    "                self.texts[idx],\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            # squeeze to 1D tensors\n",
    "            return {k: v.squeeze(0) for k, v in enc.items()}\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    if pad_id is None:\n",
    "        # Fallback to EOS if the tokenizer has no dedicated PAD\n",
    "        pad_id = tokenizer.eos_token_id\n",
    "\n",
    "    def _collate(batch):\n",
    "        input_ids_list = [b[\"input_ids\"] for b in batch]\n",
    "        if \"attention_mask\" in batch[0]:\n",
    "            attn_list = [b[\"attention_mask\"] for b in batch]\n",
    "        else:\n",
    "            # Fallback: all real tokens treated as 1s\n",
    "            attn_list = [torch.ones_like(b[\"input_ids\"]) for b in batch]\n",
    "\n",
    "        input_ids = pad_sequence(input_ids_list, batch_first=True, padding_value=pad_id)\n",
    "        attention = pad_sequence(attn_list, batch_first=True, padding_value=0)\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention}\n",
    "\n",
    "    ds = _CalibDS(texts)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=False, collate_fn=_collate)\n",
    "\n",
    "def run_static_ptq_optimum(model_fp32, tokenizer, calib_texts, out_dir=\"tinyllama-int8-static\"):\n",
    "    \"\"\"\n",
    "    Static PTQ with Optimum-Intel (INC 3.4.1) using a HuggingFace Dataset.\n",
    "    Expects a list[str] in `calib_texts`.\n",
    "    \"\"\"\n",
    "    import os, shutil\n",
    "    from datasets import Dataset as HFDataset\n",
    "    from optimum.intel.neural_compressor import INCQuantizer\n",
    "    from neural_compressor.config import PostTrainingQuantConfig\n",
    "\n",
    "    # Clean target dir\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Build HF dataset of tokenized samples\n",
    "    raw_ds = HFDataset.from_dict({\"text\": calib_texts})\n",
    "    def _tok(batch):\n",
    "        return tokenizer(batch[\"text\"], truncation=True, max_length=256)\n",
    "    calib_ds = raw_ds.map(_tok, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "    # Static PTQ: INT8 is default; do not pass dtype/precision in NC 3.4.1\n",
    "    qconfig = PostTrainingQuantConfig(\n",
    "        approach=\"static\",\n",
    "        # calibration_sampling_size=len(calib_ds),  # optional\n",
    "    )\n",
    "\n",
    "    # Initialize quantizer from in-memory model (or a model_id string)\n",
    "    quantizer = INCQuantizer.from_pretrained(model_fp32, task=\"text-generation\")\n",
    "\n",
    "    # IMPORTANT: use calibration_dataset + save_directory (no dataloader arg in this version)\n",
    "    quantizer.quantize(\n",
    "        qconfig,\n",
    "        calibration_dataset=calib_ds,\n",
    "        batch_size=4,\n",
    "        remove_unused_columns=False,  # we already produced the right columns\n",
    "        save_directory=out_dir,\n",
    "    )\n",
    "\n",
    "    return out_dir\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da140ae8-b046-48cf-b3cc-6ebc0c421901",
   "metadata": {},
   "source": [
    "# [EX-2] Prompt-Length Sensitivity Sweep\n",
    "This section:\n",
    "- Measures latency and throughput across different prompt lengths for each model.\n",
    "- Plots the results to visualize the impact of prompt length on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a879281-fdc6-4c88-a83d-acc04160d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_prompt_lengths(model_dict, tokenizer, prompt, lengths=(16, 64, 256), runs=3):\n",
    "    \"\"\"\n",
    "    For each model, measure latency & throughput across max_new_tokens.\n",
    "    Returns: {model_key: [{'L': L, 'lat': ..., 'tps': ...}, ...], ...}\n",
    "    \"\"\"\n",
    "    results = {k: [] for k in model_dict.keys()}\n",
    "    for name, model in model_dict.items():\n",
    "        for L in lengths:\n",
    "            lat, tps = measure_generate(model, tokenizer, prompt=prompt, max_new_tokens=L, runs=runs)\n",
    "            results[name].append({\"L\": L, \"lat\": lat, \"tps\": tps})\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_sweep(results):\n",
    "    \"\"\"\n",
    "    Plot (L vs latency) and (L vs throughput) for each model.\n",
    "    Uses matplotlib (no custom styles/colors).\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Latency\n",
    "    plt.figure()\n",
    "    for name, rows in results.items():\n",
    "        Ls = [r[\"L\"] for r in rows]\n",
    "        lats = [r[\"lat\"] for r in rows]\n",
    "        plt.plot(Ls, lats, marker=\"o\", label=name)\n",
    "    plt.xlabel(\"max_new_tokens\")\n",
    "    plt.ylabel(\"Latency (s)\")\n",
    "    plt.title(\"Latency vs Generation Length\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Throughput\n",
    "    plt.figure()\n",
    "    for name, rows in results.items():\n",
    "        Ls = [r[\"L\"] for r in rows]\n",
    "        tps = [r[\"tps\"] for r in rows]\n",
    "        plt.plot(Ls, tps, marker=\"o\", label=name)\n",
    "    plt.xlabel(\"max_new_tokens\")\n",
    "    plt.ylabel(\"Throughput (tok/s)\")\n",
    "    plt.title(\"Throughput vs Generation Length\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6624c6-9c4e-4b63-9fe4-5150ddce8e72",
   "metadata": {},
   "source": [
    "# [EX-3] KV-Cache and Padding-Side Ablation\n",
    "This section:\n",
    "- Evaluates the impact of KV-cache and padding-side configurations on model performance.\n",
    "- Measures latency and throughput under different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c538ce-b624-469d-bd98-d6e3c2da01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_cache_and_padding(model, tokenizer, prompt, max_new_tokens=128, runs=3):\n",
    "    \"\"\"\n",
    "    Measure under:\n",
    "      A) cache on,  padding left\n",
    "      B) cache off, padding left\n",
    "      C) cache on,  padding right\n",
    "      D) cache off, padding right\n",
    "    \"\"\"\n",
    "    original_cache = getattr(model.config, \"use_cache\", True)\n",
    "    original_pad = tokenizer.padding_side\n",
    "\n",
    "    scenarios = {\n",
    "        \"A_cache_on_left\":  (True,  \"left\"),\n",
    "        \"B_cache_off_left\": (False, \"left\"),\n",
    "        \"C_cache_on_right\": (True,  \"right\"),\n",
    "        \"D_cache_off_right\":(False, \"right\"),\n",
    "    }\n",
    "    out = {}\n",
    "    for key, (use_cache, side) in scenarios.items():\n",
    "        model.config.use_cache = use_cache\n",
    "        tokenizer.padding_side = side\n",
    "        lat, tps = measure_generate(model, tokenizer, prompt=prompt, max_new_tokens=max_new_tokens, runs=runs)\n",
    "        out[key] = {\"lat\": lat, \"tps\": tps}\n",
    "\n",
    "    # restore\n",
    "    model.config.use_cache = original_cache\n",
    "    tokenizer.padding_side = original_pad\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8faab46-8ac7-43da-94c3-ff55d6183782",
   "metadata": {},
   "source": [
    "# [EX-4] Batch Size Sensitivity (Micro-Batching)\n",
    "This section:\n",
    "- Evaluates the model's performance with different batch sizes.\n",
    "- Measures latency and per-sample throughput for each batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30db549d-ab71-462e-845a-1f38524b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_batched(model, tokenizer, prompt, batch_sizes=(1, 2, 4), max_new_tokens=128, runs=3):\n",
    "    \"\"\"\n",
    "    For B in batch_sizes, build batch by repeating prompt B times and timing a single generate().\n",
    "    Returns {B: {'lat': ..., 'tps_per_sample': ...}, ...}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for B in batch_sizes:\n",
    "        enc = tokenizer([prompt] * B, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "\n",
    "        # warmup\n",
    "        with torch.inference_mode():\n",
    "            _ = model.generate(**enc, max_new_tokens=8, use_cache=True)\n",
    "\n",
    "        lats = []\n",
    "        tputs = []\n",
    "        for _ in range(runs):\n",
    "            t0 = time.perf_counter()\n",
    "            with torch.inference_mode():\n",
    "                out = model.generate(**enc, max_new_tokens=max_new_tokens, use_cache=True)\n",
    "            t1 = time.perf_counter()\n",
    "\n",
    "            # gen length per sample (all same length due to same prompt)\n",
    "            gen_len = out.shape[1] - enc[\"input_ids\"].shape[1]\n",
    "            lat = t1 - t0\n",
    "            lats.append(lat)\n",
    "            # per-sample throughput\n",
    "            tputs.append((gen_len / lat))\n",
    "\n",
    "        results[B] = {\n",
    "            \"lat\": sum(lats)/len(lats),\n",
    "            \"tps_per_sample\": sum(tputs)/len(tputs)\n",
    "        }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3601e2-f8e4-4860-9aea-d07d3be3458d",
   "metadata": {},
   "source": [
    "# [EX-5] Disk Size and Peak Memory Accounting\n",
    "This section:\n",
    "- Contains utility functions for measuring the disk size of saved models.\n",
    "- Includes a context manager for tracking peak CPU and GPU memory usage during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b009d187-6dda-4431-8a15-89826da73dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_measure_size(model, tokenizer, out_dir: str) -> int | None:\n",
    "    \"\"\"\n",
    "    Save model+tokenizer to `out_dir` and return total size in BYTES.\n",
    "    Robust to dynamic INT8 models that can't use `save_pretrained`.\n",
    "    \"\"\"\n",
    "    import os, shutil, json, torch\n",
    "    from pathlib import Path\n",
    "\n",
    "    p = Path(out_dir)\n",
    "    if p.exists():\n",
    "        shutil.rmtree(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Always try to save tokenizer (helps count comparable metadata)\n",
    "    if getattr(tokenizer, \"pad_token_id\", None) is None and getattr(tokenizer, \"eos_token_id\", None) is not None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    try:\n",
    "        tokenizer.save_pretrained(p.as_posix())\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] tokenizer.save_pretrained failed: {e}\")\n",
    "\n",
    "    # 1) Try HF-native save_pretrained (works for FP32/most normal models)\n",
    "    ok = False\n",
    "    try:\n",
    "        model.save_pretrained(p.as_posix(), safe_serialization=True)\n",
    "        ok = True\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] save_pretrained failed, falling back: {e}\")\n",
    "\n",
    "    if not ok:\n",
    "        # 2) Fallback: raw state_dict (may still fail for some quantized modules)\n",
    "        try:\n",
    "            (p / \"config.json\").write_text(\n",
    "                getattr(model, \"config\", None).to_json_string() if hasattr(model, \"config\") else \"{}\"\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            torch.save(model.state_dict(), p / \"pytorch_model_state_dict.pt\")\n",
    "            ok = True\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] torch.save(state_dict) failed, last resort pickle: {e}\")\n",
    "            # 3) Last resort: pickle the whole model object (we only need bytes-on-disk)\n",
    "            try:\n",
    "                torch.save(model, p / \"model_pickle.pt\")\n",
    "                ok = True\n",
    "            except Exception as e2:\n",
    "                print(f\"[error] torch.save(model) also failed: {e2}\")\n",
    "                return None\n",
    "\n",
    "    # Compute total bytes\n",
    "    total = 0\n",
    "    for root, _, files in os.walk(p):\n",
    "        for f in files:\n",
    "            total += os.path.getsize(os.path.join(root, f))\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "class PeakMemory:\n",
    "    \"\"\"\n",
    "    Context manager to record peak CPU (and GPU if available) memory during a block.\n",
    "    CPU via psutil RSS; GPU via torch.cuda.max_memory_allocated().\n",
    "    \"\"\"\n",
    "    def __enter__(self):\n",
    "        import psutil\n",
    "        self._psutil = psutil\n",
    "        self._proc = psutil.Process(os.getpid())\n",
    "        self.cpu_peak_bytes = self._proc.memory_info().rss\n",
    "        self.gpu_peak_bytes = 0\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        # CPU: we sample once at the end (simple approach).\n",
    "        self.cpu_peak_bytes = max(self.cpu_peak_bytes, self._proc.memory_info().rss)\n",
    "        if torch.cuda.is_available():\n",
    "            self.gpu_peak_bytes = torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc2eb3-a382-4cd3-843b-852291abbe9f",
   "metadata": {},
   "source": [
    "# [EX-6] Quality Proxy: Pseudo-Perplexity\n",
    "This section:\n",
    "- Implements pseudo-perplexity as a quality proxy for the models.\n",
    "- Measures how well the model predicts tokens in a leave-one-out style evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53645c63-3689-49a5-a5e2-97ffa7180ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def pseudo_perplexity(model, tokenizer, text, max_len=128):\n",
    "    \"\"\"\n",
    "    Leave-one-out style pseudo-perplexity.\n",
    "    \"\"\"\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n",
    "    input_ids = enc[\"input_ids\"].to(DEVICE)\n",
    "    attn = enc[\"attention_mask\"].to(DEVICE)\n",
    "    n = input_ids.shape[1]\n",
    "    if n < 2:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    loss_sum = 0.0\n",
    "    steps = 0\n",
    "    for i in range(1, n):  # predict token i given 0..i-1\n",
    "        out = model(input_ids=input_ids[:, :i], attention_mask=attn[:, :i])\n",
    "        logits = out.logits[:, -1, :]\n",
    "        target = input_ids[:, i]\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target)\n",
    "        loss_sum += loss.item()\n",
    "        steps += 1\n",
    "    avg_loss = loss_sum / max(1, steps)\n",
    "    return math.exp(avg_loss)\n",
    "\n",
    "\n",
    "def compare_ppplx(models, tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Compute pseudo-perplexity for each model over `texts` (list[str]).\n",
    "    Return: {model_key: [scores...], ...}\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    for name, model in models.items():\n",
    "        scores[name] = [pseudo_perplexity(model, tokenizer, t) for t in texts]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d4e09-d4b1-4e5e-93a4-dee1b2ce7227",
   "metadata": {},
   "source": [
    "# [EX-7] Results Table and Reflection\n",
    "This section:\n",
    "- Builds a results table summarizing the evaluation metrics for all models.\n",
    "- Includes metrics such as size, latency, throughput, and pseudo-perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1a5d1-0212-43b7-af46-33f83d396b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_table(metrics_rows):\n",
    "    \"\"\"\n",
    "    Build a pandas DataFrame from list of dicts.\n",
    "    Expected keys per row:\n",
    "      precision, size_bytes, lat_64, tps_64, lat_256, tps_256, ppplx_avg\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(metrics_rows)\n",
    "    # add human-readable MB\n",
    "    if \"size_bytes\" in df.columns:\n",
    "        df[\"size_MB\"] = df[\"size_bytes\"].apply(lambda b: round(b/1024/1024, 1) if pd.notnull(b) else None)\n",
    "    return df[[\n",
    "        c for c in [\n",
    "            \"precision\",\"size_bytes\",\"size_MB\",\n",
    "            \"lat_64\",\"tps_64\",\"lat_256\",\"tps_256\",\"ppplx_avg\"\n",
    "        ] if c in df.columns\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3cd0d-83d9-4537-9abd-aa103436beff",
   "metadata": {},
   "source": [
    "# [EX-8 - Stretch] Edge-Case Prompts Check\n",
    "This section:\n",
    "- Tests the models with edge-case prompts to evaluate their robustness.\n",
    "- Generates outputs for challenging prompts and compares the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e282aaa1-fdcc-43cb-82e2-f5f2f526c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_edge_prompts(models, tokenizer, prompts, max_new_tokens=64):\n",
    "    \"\"\"\n",
    "    Generate for a small set of edge prompts.\n",
    "    Returns: {model_key: [decoded_outputs...], ...}\n",
    "    \"\"\"\n",
    "    outputs = {k: [] for k in models.keys()}\n",
    "    for name, model in models.items():\n",
    "        for p in prompts:\n",
    "            enc = tokenizer(p, return_tensors=\"pt\").to(DEVICE)\n",
    "            with torch.inference_mode():\n",
    "                out_ids = model.generate(**enc, max_new_tokens=max_new_tokens, use_cache=True)\n",
    "            outputs[name].append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b4f84-09b6-4e5c-bfd2-0405e6146213",
   "metadata": {},
   "source": [
    "# Master Controller for the Quantization Exercise\n",
    "This cell:\n",
    "- Orchestrates the execution of all parts of the quantization exercise.\n",
    "- Runs experiments such as prompt-length sweep, cache/padding ablation, and batch-size sensitivity.\n",
    "- Collects and summarizes results in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc24a702-73bc-4e0c-96fc-8b8f2d655ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quantization_exercise(model_fp32, model_int8, tok, PROMPT, save_and_measure_size, PeakMemory):\n",
    "    \"\"\"\n",
    "    Runs: length sweep, cache/padding ablation, batching, size+memory, pseudo-perplexity, edge prompts.\n",
    "    Assumes:\n",
    "      - measure_generate() returns (lat, tps)\n",
    "      - sweep_prompt_lengths(), ablate_cache_and_padding(), measure_batched(),\n",
    "        compare_ppplx(), build_results_table(), probe_edge_prompts() are defined.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the model registry for experiments\n",
    "    models = {\"fp32\": model_fp32}\n",
    "    if model_int8 is not None:\n",
    "        models[\"int8-dyn\"] = model_int8\n",
    "\n",
    "    # Helper to pull metrics from sweep results\n",
    "    def _get_metric(sweep, model_key, L, field):\n",
    "        rows = sweep.get(model_key, [])\n",
    "        for r in rows:\n",
    "            if r.get(\"L\") == L:\n",
    "                return r.get(field)\n",
    "        return None\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1) Prompt-length sensitivity sweep\n",
    "    # -------------------------------\n",
    "    print(\"\\n[1] Prompt-length sweep\")\n",
    "    sweep_results = sweep_prompt_lengths(models, tok, PROMPT, lengths=(16, 64, 256))\n",
    "    plot_sweep(sweep_results)\n",
    "\n",
    "    # Choose a reference model for later steps\n",
    "    ref_key = \"int8-dyn\" if \"int8-dyn\" in models else \"fp32\"\n",
    "    ref_model = models[ref_key]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) KV-cache & padding ablation (on the reference model)\n",
    "    # -------------------------------\n",
    "    print(f\"\\n[2] Cache & padding ablation (on: {ref_key})\")\n",
    "    ablation = ablate_cache_and_padding(ref_model, tok, PROMPT)\n",
    "    print(\"Ablation results:\", ablation)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) Batch-size sensitivity (on the reference model)\n",
    "    # -------------------------------\n",
    "    print(f\"\\n[3] Batch-size sensitivity (on: {ref_key})\")\n",
    "    batch_res = measure_batched(ref_model, tok, PROMPT)\n",
    "    print(\"Batch results:\", batch_res)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4) Model size + memory tracking\n",
    "    # -------------------------------\n",
    "    print(\"\\n[4] Model size + memory\")\n",
    "    size_fp32 = save_and_measure_size(model_fp32, tok, \"fp32-save\")\n",
    "    size_int8_dyn = save_and_measure_size(model_int8, tok, \"int8dyn-save\") if \"int8-dyn\" in models else None\n",
    "\n",
    "    with PeakMemory() as pm:\n",
    "        _ = measure_generate(ref_model, tok, PROMPT, max_new_tokens=64)\n",
    "    print(\"Peak memory (CPU/GPU):\", pm.cpu_peak_bytes, pm.gpu_peak_bytes)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5) Quality proxy: pseudo-perplexity\n",
    "    # -------------------------------\n",
    "    print(\"\\n[5] Quality proxy (pseudo-perplexity)\")\n",
    "    texts = [\"Quantization reduces model size.\", \"Speed matters for deployment.\"]\n",
    "    ppplx_scores = compare_ppplx(models, tok, texts)\n",
    "    print(\"PPPLX:\", ppplx_scores)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6) Build results table\n",
    "    # -------------------------------\n",
    "    print(\"\\n[6] Summary table\")\n",
    "    metrics = []\n",
    "\n",
    "    metrics.append({\n",
    "        \"precision\": \"FP32\",\n",
    "        \"size_bytes\": size_fp32,\n",
    "        \"lat_64\":  _get_metric(sweep_results, \"fp32\", 64,  \"lat\"),\n",
    "        \"tps_64\":  _get_metric(sweep_results, \"fp32\", 64,  \"tps\"),\n",
    "        \"lat_256\": _get_metric(sweep_results, \"fp32\", 256, \"lat\"),\n",
    "        \"tps_256\": _get_metric(sweep_results, \"fp32\", 256, \"tps\"),\n",
    "        \"ppplx_avg\": (sum(ppplx_scores.get(\"fp32\", [])) / max(1, len(ppplx_scores.get(\"fp32\", []))))\n",
    "    })\n",
    "\n",
    "    if \"int8-dyn\" in models:\n",
    "        metrics.append({\n",
    "            \"precision\": \"INT8-dyn (CPU)\",\n",
    "            \"size_bytes\": size_int8_dyn,\n",
    "            \"lat_64\":  _get_metric(sweep_results, \"int8-dyn\", 64,  \"lat\"),\n",
    "            \"tps_64\":  _get_metric(sweep_results, \"int8-dyn\", 64,  \"tps\"),\n",
    "            \"lat_256\": _get_metric(sweep_results, \"int8-dyn\", 256, \"lat\"),\n",
    "            \"tps_256\": _get_metric(sweep_results, \"int8-dyn\", 256, \"tps\"),\n",
    "            \"ppplx_avg\": (sum(ppplx_scores.get(\"int8-dyn\", [])) / max(1, len(ppplx_scores.get(\"int8-dyn\", []))))\n",
    "        })\n",
    "\n",
    "    df = build_results_table(metrics)\n",
    "    print(df)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7) (Stretch) Edge prompts\n",
    "    # -------------------------------\n",
    "    print(\"\\n[7] Edge-case prompts\")\n",
    "    edge_prompts = [\n",
    "        \"Supercalifragilisticexpialidocious\",\n",
    "        \"12345678901234567890\",\n",
    "        \"A very very very very very long name...\",\n",
    "    ]\n",
    "    outputs = probe_edge_prompts(models, tok, edge_prompts)\n",
    "    for m, outs in outputs.items():\n",
    "        print(f\"--- {m} ---\")\n",
    "        for o in outs:\n",
    "            print(o)\n",
    "            print(\"=\" * 40)\n",
    "\n",
    "    return {\n",
    "        \"sweep\": sweep_results,\n",
    "        \"ablation\": ablation,\n",
    "        \"batch\": batch_res,\n",
    "        \"sizes\": (size_fp32, size_int8_dyn),\n",
    "        \"ppplx\": ppplx_scores,\n",
    "        \"table\": df,\n",
    "        \"edge_outputs\": outputs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859c787",
   "metadata": {},
   "source": [
    "# Run the Quantization Exercise\n",
    "This cell:\n",
    "- Executes the master controller function to run all parts of the quantization exercise.\n",
    "- Collects and prints the results for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5a70128-3f1e-41d2-8c40-d10aaf7bf47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Prompt-length sweep\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Cache & padding ablation (on: int8-dyn)\n",
      "Ablation results: {'A_cache_on_left': {'lat': 0.22545417064490417, 'tps': 4.436752856085373}, 'B_cache_off_left': {'lat': 0.1691590944149842, 'tps': 8.514883360395713}, 'C_cache_on_right': {'lat': 0.16918594700594744, 'tps': 7.0528541734662875}, 'D_cache_off_right': {'lat': 0.2036272215967377, 'tps': 5.001046873875578}}\n",
      "\n",
      "[3] Batch-size sensitivity (on: int8-dyn)\n",
      "Batch results: {1: {'lat': 0.1129904785969605, 'tps_per_sample': 10.53523427399191}, 2: {'lat': 0.18161187569300333, 'tps_per_sample': 7.295849081359471}, 4: {'lat': 0.21545228261190155, 'tps_per_sample': 5.545868262145601}}\n",
      "\n",
      "[4] Model size + memory\n",
      "[warn] save_pretrained failed, falling back: 'torch.dtype' object has no attribute 'data_ptr'\n",
      "Peak memory (CPU/GPU): 11152576512 5776738304\n",
      "\n",
      "[5] Quality proxy (pseudo-perplexity)\n",
      "PPPLX: {'fp32': [467.89175668934826, 6308.311311027291], 'int8-dyn': [494.62983688680976, 6558.688527128666]}\n",
      "\n",
      "[6] Summary table\n",
      "        precision  size_bytes  size_MB    lat_64    tps_64   lat_256  \\\n",
      "0            FP32  4402561934   4198.6  0.769397  1.320457  0.690350   \n",
      "1  INT8-dyn (CPU)  1299487389   1239.3  0.167361  7.471518  0.225566   \n",
      "\n",
      "    tps_256    ppplx_avg  \n",
      "0  1.453980  3388.101534  \n",
      "1  4.434512  3526.659182  \n",
      "\n",
      "[7] Edge-case prompts\n",
      "--- fp32 ---\n",
      "Supercalifragilisticexpialidocious!\n",
      "\n",
      "Scene 2:\n",
      "The stage is now set for the musical number \"I'm Gonna Wash That Man Right Outta My Hair!\"\n",
      "\n",
      "The chorus begins to sing:\n",
      "\n",
      "Chorus:\n",
      "I'm gonna wash that man right outta my hair!\n",
      "========================================\n",
      "123456789012345678901234567890123456789012345678901234567890123456789012345678901234\n",
      "========================================\n",
      "A very very very very very long name...\n",
      "\n",
      "I hope this helps!\n",
      "========================================\n",
      "--- int8-dyn ---\n",
      "Supercalifragilisticexpialidocious.\n",
      "\n",
      "The song's lyrics are a reflection of the author's personal experiences, including the challenges of finding love and the emotional toll of heartbreak. The song's melody and instrumentation are reminiscent of classic rock and roll, with a driving beat and catchy\n",
      "========================================\n",
      "123456789012345678901234567890123456789012345678901234567890123456789012345678901234\n",
      "========================================\n",
      "A very very very very very long name...\n",
      "\n",
      "2. \"The Great Gatsby\" by F. Scott Fitzgerald - A very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "results = run_quantization_exercise(model_fp32, model_int8, tok, PROMPT, save_and_measure_size, PeakMemory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361cc503",
   "metadata": {},
   "source": [
    "# Additional Notes or Code\n",
    "This cell is reserved for any additional notes or code that may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239912b-e168-4344-9dd9-cf278bf884bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
