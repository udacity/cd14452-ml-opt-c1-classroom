{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8563c42",
   "metadata": {},
   "source": [
    "# üèãÔ∏è Exercise 1 ‚Äî **Solution Notebook** (Built on the Demo)\n",
    "\n",
    "This is the **worked solution** that *extends* the demo rather than repeating it.\n",
    "All original demo cells appear **below** unchanged. The solution tasks are implemented\n",
    "in the new cells you see **above** the demo.\n",
    " \n",
    "**Scope:** \n",
    "- CIFAR‚Äë10 loaders with knobs.\n",
    "- Quick training/evaluation loops.\n",
    "- Model comparison.\n",
    "- Profiling with TensorBoard.\n",
    "- Ablations for batch size and `num_workers`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5461f",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup\n",
    "\n",
    "This cell:\n",
    "- Imports PyTorch, TorchVision, and utility packages used across all tasks.\n",
    "- Sets the device to GPU if available, otherwise defaults to CPU.\n",
    "- Prints the device being used for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64d3845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 19:59:44.120140: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-24 19:59:44.133458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-24 19:59:44.151182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-24 19:59:44.156662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-24 19:59:44.169521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os, time, math, json, shutil, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# TensorBoard logging (for profiler traces & scalars)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12659a92",
   "metadata": {},
   "source": [
    "## Task A ‚Äî üîÑ Central Knobs for DataLoaders (Batch Size, Num Workers)\n",
    "\n",
    "This section:\n",
    "- Builds reusable CIFAR‚Äë10 DataLoaders with configurable batch size and number of workers.\n",
    "- Defines:\n",
    "  - `_ex1_build_datasets`: Creates CIFAR‚Äë10 training and test datasets with standard normalization.\n",
    "  - `_ex1_build_loaders`: Builds DataLoaders for the datasets.\n",
    "  - `set_ex1_dataloader_params`: Updates DataLoader parameters and rebuilds the loaders.\n",
    "- Ensures flexibility for experimentation with different DataLoader configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3bbf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170498071/170498071 [00:01<00:00, 106105046.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "DataLoader params: {'batch_size': 128, 'num_workers': 2}\n"
     ]
    }
   ],
   "source": [
    "# ---- DataLoader builder with knobs ----\n",
    "_ex1_datasets = {}\n",
    "_ex1_loaders = {}\n",
    "_ex1_cfg = {\"batch_size\": 128, \"num_workers\": 2}\n",
    "\n",
    "def _ex1_build_datasets():\n",
    "    global _ex1_datasets\n",
    "    if _ex1_datasets:\n",
    "        return _ex1_datasets\n",
    "    # Standard CIFAR-10 normalization\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    train_ds = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "    test_ds  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "    _ex1_datasets = {\"train\": train_ds, \"test\": test_ds}\n",
    "    return _ex1_datasets\n",
    "\n",
    "def _ex1_build_loaders():\n",
    "    global _ex1_loaders\n",
    "    ds = _ex1_build_datasets()\n",
    "    bs = _ex1_cfg[\"batch_size\"]\n",
    "    nw = _ex1_cfg[\"num_workers\"]\n",
    "    train_loader = DataLoader(ds[\"train\"], batch_size=bs, shuffle=True,  num_workers=nw, pin_memory=True)\n",
    "    test_loader  = DataLoader(ds[\"test\"],  batch_size=bs, shuffle=False, num_workers=nw, pin_memory=True)\n",
    "    _ex1_loaders = {\"train\": train_loader, \"test\": test_loader}\n",
    "    return _ex1_loaders\n",
    "\n",
    "def set_ex1_dataloader_params(batch_size=128, num_workers=2):\n",
    "    \"\"\"Update loader knobs and rebuild loaders.\"\"\"\n",
    "    _ex1_cfg[\"batch_size\"] = int(batch_size)\n",
    "    _ex1_cfg[\"num_workers\"] = int(num_workers)\n",
    "    # Force rebuild\n",
    "    _ex1_loaders.clear()\n",
    "    return _ex1_build_loaders()\n",
    "\n",
    "# Build initial loaders\n",
    "_ = set_ex1_dataloader_params(batch_size=128, num_workers=2)\n",
    "print(\"DataLoader params:\", _ex1_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c577a",
   "metadata": {},
   "source": [
    "## Utility ‚Äî üß© Small Model Zoo and Quick Train/Eval\n",
    "\n",
    "This section:\n",
    "- Provides utility functions for training and evaluating models.\n",
    "- Defines:\n",
    "  - `get_ex1_model`: Loads small models like ResNet-18, ResNet-34, or MobileNetV2 with 10 output classes.\n",
    "  - `ex1_train_one_epoch`: Trains the model for one epoch with optional step limits for quick runs.\n",
    "  - `ex1_eval_one_epoch`: Evaluates the model for one epoch, computing accuracy and throughput.\n",
    "- Measures throughput in samples per second for both training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed883fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Models ----\n",
    "def get_ex1_model(name: str):\n",
    "    name = name.lower()\n",
    "    if name == \"resnet18\":\n",
    "        m = torchvision.models.resnet18(weights=None, num_classes=10)\n",
    "    elif name == \"resnet34\":\n",
    "        m = torchvision.models.resnet34(weights=None, num_classes=10)\n",
    "    elif name in (\"mobilenet_v2\", \"mbv2\"):\n",
    "        m = torchvision.models.mobilenet_v2(weights=None, num_classes=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {name}\")\n",
    "    return m.to(device)\n",
    "\n",
    "# ---- Train / Eval helpers ----\n",
    "def ex1_train_one_epoch(model, loader, optimizer, criterion, max_steps=None):\n",
    "    model.train()\n",
    "    n_seen = 0\n",
    "    t0 = time.time()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        if max_steps is not None and step >= max_steps:\n",
    "            break\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        n_seen += x.size(0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    throughput = n_seen / (t1 - t0) if (t1 - t0) > 0 else float('nan')\n",
    "    return {\n",
    "        \"loss\": total_loss / max(1, n_seen),\n",
    "        \"num_samples\": n_seen,\n",
    "        \"latency_s\": t1 - t0,\n",
    "        \"throughput_samp_per_s\": throughput,\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def ex1_eval_one_epoch(model, loader, criterion, max_steps=None):\n",
    "    model.eval()\n",
    "    n_seen = 0\n",
    "    correct = 0\n",
    "    t0 = time.time()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        if max_steps is not None and step >= max_steps:\n",
    "            break\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        n_seen += x.size(0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    throughput = n_seen / (t1 - t0) if (t1 - t0) > 0 else float('nan')\n",
    "    accuracy = correct / max(1, n_seen)\n",
    "    return {\n",
    "        \"loss\": total_loss / max(1, n_seen),\n",
    "        \"acc\": accuracy,\n",
    "        \"num_samples\": n_seen,\n",
    "        \"latency_s\": t1 - t0,\n",
    "        \"throughput_samp_per_s\": throughput,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01522c",
   "metadata": {},
   "source": [
    "### üöÄ Quick Smoke Run (Task A Deliverable)\n",
    "\n",
    "This cell:\n",
    "- Runs a short training and evaluation loop to verify that the DataLoaders and model are working correctly.\n",
    "- Limits the number of steps to ensure the run is quick.\n",
    "- Prints training and validation statistics, including loss, throughput, and latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628ac72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stats: {'loss': 4.506065475940704, 'num_samples': 2560, 'latency_s': 1.396545648574829, 'throughput_samp_per_s': 1833.0943944528221}\n",
      "Val   stats: {'loss': 621.117073059082, 'acc': 0.0984375, 'num_samples': 2560, 'latency_s': 0.40219855308532715, 'throughput_samp_per_s': 6365.0154391701435}\n"
     ]
    }
   ],
   "source": [
    "# ---- Task A: quick run ----\n",
    "loaders = set_ex1_dataloader_params(batch_size=128, num_workers=2)\n",
    "train_loader, test_loader = loaders[\"train\"], loaders[\"test\"]\n",
    "\n",
    "model = get_ex1_model(\"resnet18\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "train_stats = ex1_train_one_epoch(model, train_loader, optimizer, criterion, max_steps=20)\n",
    "val_stats   = ex1_eval_one_epoch(model, test_loader, criterion, max_steps=20)\n",
    "\n",
    "print(\"Train stats:\", train_stats)\n",
    "print(\"Val   stats:\", val_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996e1d2",
   "metadata": {},
   "source": [
    "## Task B ‚Äî üÜö Add a Second Model and Compare\n",
    "\n",
    "This section:\n",
    "- Compares the performance of two models (`resnet18` and `resnet34`) using the same pipeline.\n",
    "- Measures training and evaluation metrics for both models.\n",
    "- Returns a dictionary containing the results for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e704ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resnet18': {'train': {'loss': 4.539602792263031,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 0.9383394718170166,\n",
       "   'throughput_samp_per_s': 2728.223715285868},\n",
       "  'val': {'loss': 15.011657333374023,\n",
       "   'acc': 0.110546875,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 0.3471341133117676,\n",
       "   'throughput_samp_per_s': 7374.67134986188}},\n",
       " 'resnet34': {'train': {'loss': 5.312578654289245,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 1.404033899307251,\n",
       "   'throughput_samp_per_s': 1823.3177997077576},\n",
       "  'val': {'loss': 349704.790625,\n",
       "   'acc': 0.1046875,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 0.36156678199768066,\n",
       "   'throughput_samp_per_s': 7080.296441658243}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Task B: compare two models under same loaders ----\n",
    "def ex1_compare_models(model_names=(\"resnet18\",\"resnet34\"), max_steps=20):\n",
    "    results = {}\n",
    "    for name in model_names:\n",
    "        m = get_ex1_model(name)\n",
    "        opt = optim.SGD(m.parameters(), lr=0.1, momentum=0.9)\n",
    "        tr = ex1_train_one_epoch(m, train_loader, opt, criterion, max_steps=max_steps)\n",
    "        ev = ex1_eval_one_epoch(m, test_loader, criterion, max_steps=max_steps)\n",
    "        results[name] = {\"train\": tr, \"val\": ev}\n",
    "    return results\n",
    "\n",
    "compare_models = ex1_compare_models(model_names=(\"resnet18\",\"resnet34\"), max_steps=20)\n",
    "compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847bf2f",
   "metadata": {},
   "source": [
    "## Task C ‚Äî üìä PyTorch Profiler ‚Üí TensorBoard (Top Ops)\n",
    "\n",
    "This section:\n",
    "- Profiles the training loop using PyTorch Profiler.\n",
    "- Saves profiling traces to TensorBoard for visualization.\n",
    "- Captures:\n",
    "  - Operator-level performance metrics.\n",
    "  - CUDA and CPU activity.\n",
    "  - Memory usage.\n",
    "- Prints the top operators by total CUDA or CPU time.\n",
    "- Provides a path to the TensorBoard logs for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb48122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-08-24 19:59:57 26644:26644 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-08-24 19:59:57 26644:26644 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-08-24 19:59:57 26644:26644 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.51%     529.000us         5.66%       5.827ms     145.675us       0.000us         0.00%      50.437ms       1.261ms           0 b           0 b      53.70 Mb     -72.75 Mb            40  \n",
      "                                   ConvolutionBackward0         0.25%     255.000us         4.86%       5.004ms     125.100us       0.000us         0.00%      50.236ms       1.256ms           0 b           0 b     126.45 Mb           0 b            40  \n",
      "                             aten::convolution_backward         3.03%       3.115ms         4.61%       4.749ms     118.725us      50.236ms        51.60%      50.236ms       1.256ms           0 b           0 b     126.45 Mb      41.00 Mb            40  \n",
      "void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3...         0.00%       0.000us         0.00%       0.000us       0.000us      47.360ms        48.65%      47.360ms       1.894ms           0 b           0 b           0 b           0 b            25  \n",
      "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us      14.815ms        15.22%      14.815ms       7.407ms           0 b           0 b           0 b           0 b             2  \n",
      "                                          ProfilerStep*        18.81%      19.365ms        67.02%      68.990ms      34.495ms       0.000us         0.00%      12.074ms       6.037ms           0 b           0 b           0 b     -32.29 Mb             2  \n",
      "                                           aten::conv2d         0.15%     154.000us         3.44%       3.544ms      88.600us       0.000us         0.00%       7.125ms     178.125us           0 b           0 b      51.50 Mb           0 b            40  \n",
      "                                      aten::convolution         0.34%     353.000us         3.29%       3.390ms      84.750us       0.000us         0.00%       7.125ms     178.125us           0 b           0 b      51.50 Mb           0 b            40  \n",
      "                                     aten::_convolution         0.25%     261.000us         2.95%       3.037ms      75.925us       0.000us         0.00%       7.125ms     178.125us           0 b           0 b      51.50 Mb           0 b            40  \n",
      "                                aten::cudnn_convolution         1.87%       1.927ms         2.70%       2.776ms      69.400us       7.125ms         7.32%       7.125ms     178.125us           0 b           0 b      51.50 Mb      51.50 Mb            40  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 102.944ms\n",
      "Self CUDA time total: 97.354ms\n",
      "\n",
      "Profiler traces saved to: ./runs/ex1_solution. Launch TensorBoard pointing to this folder.\n"
     ]
    }
   ],
   "source": [
    "# ---- Task C: Profiler to TensorBoard ----\n",
    "from torch.profiler import profile, ProfilerActivity, schedule\n",
    "\n",
    "log_dir = \"./runs/ex1_solution\"\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "model_prof = get_ex1_model(\"resnet18\")\n",
    "opt_prof = optim.SGD(model_prof.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# A tiny schedule to keep it quick\n",
    "sched = schedule(wait=1, warmup=1, active=2, repeat=1)\n",
    "\n",
    "top_ops = []\n",
    "\n",
    "def _trace_handler(p):\n",
    "    # Save Chrome trace\n",
    "    p.export_chrome_trace(os.path.join(log_dir, \"trace.json\"))\n",
    "    # Collect simple top-ops by total CUDA time if available, else CPU total\n",
    "    try:\n",
    "        evt = p.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10)\n",
    "    except Exception:\n",
    "        evt = p.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)\n",
    "    print(evt)\n",
    "\n",
    "activities = [ProfilerActivity.CPU]\n",
    "if device.type == \"cuda\":\n",
    "    activities.append(ProfilerActivity.CUDA)\n",
    "\n",
    "with profile(activities=activities,\n",
    "             schedule=sched,\n",
    "             on_trace_ready=_trace_handler,\n",
    "             record_shapes=True,\n",
    "             profile_memory=True,\n",
    "             with_stack=False) as prof:\n",
    "\n",
    "    steps = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt_prof.zero_grad()\n",
    "        out = model_prof(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        opt_prof.step()\n",
    "\n",
    "        prof.step()\n",
    "        steps += 1\n",
    "        if steps >= 20:\n",
    "            break\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n",
    "print(f\"Profiler traces saved to: {log_dir}. Launch TensorBoard pointing to this folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98999c2",
   "metadata": {},
   "source": [
    "## Task D ‚Äî üî¨ Ablations: Batch Size & `num_workers`\n",
    "\n",
    "This section:\n",
    "- Sweeps through different configurations of batch size and number of workers.\n",
    "- Measures training and validation throughput for each configuration.\n",
    "- Returns the results as a pandas DataFrame for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f24dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>train_throughput</th>\n",
       "      <th>val_throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2867.734725</td>\n",
       "      <td>5682.424407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2885.691414</td>\n",
       "      <td>7082.141089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>2751.918987</td>\n",
       "      <td>9267.580045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  num_workers  train_throughput  val_throughput\n",
       "0          64            2       2867.734725     5682.424407\n",
       "1         128            2       2885.691414     7082.141089\n",
       "2         128            4       2751.918987     9267.580045"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Task D: Ablations ----\n",
    "import pandas as pd\n",
    "\n",
    "def ex1_ablate(configs=((64,2),(128,2),(128,4)), max_steps=20):\n",
    "    rows = []\n",
    "    for bs, nw in configs:\n",
    "        set_ex1_dataloader_params(bs, nw)\n",
    "        m = get_ex1_model(\"resnet18\")\n",
    "        opt = optim.SGD(m.parameters(), lr=0.1, momentum=0.9)\n",
    "        tr = ex1_train_one_epoch(m, _ex1_loaders[\"train\"], opt, criterion, max_steps=max_steps)\n",
    "        ev = ex1_eval_one_epoch(m, _ex1_loaders[\"test\"], criterion, max_steps=max_steps)\n",
    "        rows.append({\n",
    "            \"batch_size\": bs,\n",
    "            \"num_workers\": nw,\n",
    "            \"train_throughput\": tr[\"throughput_samp_per_s\"],\n",
    "            \"val_throughput\": ev[\"throughput_samp_per_s\"],\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_abl = ex1_ablate(configs=((64,2),(128,2),(128,4)), max_steps=20)\n",
    "df_abl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c3486",
   "metadata": {},
   "source": [
    "## üîç Launch TensorBoard\n",
    "\n",
    "This cell:\n",
    "- Launches TensorBoard to visualize the profiling traces saved in the `./runs/ex1_solution` directory.\n",
    "- Opens TensorBoard on port 6006, accessible via the host's browser.\n",
    "\n",
    "### Launch TensorBoard from VS Code (UI way)\n",
    "\n",
    "- Open the project folder in VS Code.\n",
    "\n",
    "- Press `Ctrl/Cmd + Shift + P` ‚Üí run ‚ÄúPython: Launch TensorBoard‚Äù (or ‚ÄúLaunch TensorBoard‚Äù).\n",
    "\n",
    "- Choose your log directory (e.g., `runs/` or `logs/`), pick a port (default `6006`).\n",
    "\n",
    "- TensorBoard opens in an editor tab (or your browser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1d4a8-eb96-4a0f-878d-c820caf27df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs/ex1_solution --host 0.0.0.0 --port 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
