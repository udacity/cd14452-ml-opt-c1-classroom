{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8563c42",
   "metadata": {},
   "source": [
    "# Exercise 1 — **Solution Notebook** (Built on the Demo)\n",
    "\n",
    "This is the **worked solution** that *extends* the demo rather than repeating it.\n",
    "All original demo cells appear **below** unchanged. The solution tasks are implemented\n",
    "in the new cells you see **above** the demo.\n",
    "\n",
    "**Generated:** 2025-08-24 19:57:12  \n",
    "**Scope:** CIFAR‑10 loaders with knobs, quick training/eval, model comparison, profiler→TensorBoard, and ablations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5461f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This cell imports PyTorch, TorchVision, and utility packages used across all tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64d3845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 19:59:44.120140: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-24 19:59:44.133458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-24 19:59:44.151182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-24 19:59:44.156662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-24 19:59:44.169521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os, time, math, json, shutil, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# TensorBoard logging (for profiler traces & scalars)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12659a92",
   "metadata": {},
   "source": [
    "## Task A — Central knobs for DataLoaders (batch size, num_workers)\n",
    "\n",
    "We build **reusable CIFAR‑10 dataloaders** and expose knobs via `set_ex1_dataloader_params`.\n",
    "If your demo already defines loaders, you can *ignore them* and just use these solution loaders,\n",
    "or adapt the function to call your demo's builder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3bbf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:01<00:00, 106105046.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "DataLoader params: {'batch_size': 128, 'num_workers': 2}\n"
     ]
    }
   ],
   "source": [
    "# ---- DataLoader builder with knobs ----\n",
    "_ex1_datasets = {}\n",
    "_ex1_loaders = {}\n",
    "_ex1_cfg = {\"batch_size\": 128, \"num_workers\": 2}\n",
    "\n",
    "def _ex1_build_datasets():\n",
    "    \"\"\"\n",
    "    TODO: Create CIFAR-10 train/test datasets with standard transforms.\n",
    "      - Train transforms: RandomCrop(32, padding=4), RandomHorizontalFlip(), ToTensor(), Normalize(mean,std)\n",
    "      - Test  transforms: ToTensor(), Normalize(mean,std)\n",
    "      - Use root=\"./data\", set train=True/False, download=True\n",
    "      - Return a dict: {\"train\": train_ds, \"test\": test_ds}\n",
    "    Hints:\n",
    "      - mean = (0.4914, 0.4822, 0.4465)\n",
    "      - std  = (0.2023, 0.1994, 0.2010)\n",
    "    \"\"\"\n",
    "    global _ex1_datasets\n",
    "    if _ex1_datasets:\n",
    "        return _ex1_datasets\n",
    "\n",
    "    raise NotImplementedError(\"Implement _ex1_build_datasets() per the TODO comments\")\n",
    "\n",
    "def _ex1_build_loaders():\n",
    "    \"\"\"\n",
    "    TODO: Build DataLoaders from the datasets with params in _ex1_cfg.\n",
    "      - Read batch_size and num_workers from _ex1_cfg\n",
    "      - train loader: shuffle=True, pin_memory=True\n",
    "      - test  loader: shuffle=False, pin_memory=True\n",
    "      - Return a dict: {\"train\": train_loader, \"test\": test_loader}\n",
    "    \"\"\"\n",
    "    global _ex1_loaders\n",
    "    raise NotImplementedError(\"Implement _ex1_build_loaders() per the TODO comments\")\n",
    "\n",
    "def set_ex1_dataloader_params(batch_size=128, num_workers=2):\n",
    "    \"\"\"\n",
    "    Update loader knobs and rebuild loaders.\n",
    "\n",
    "    TODO:\n",
    "      - Cast inputs to int and store in _ex1_cfg\n",
    "      - Clear _ex1_loaders cache to force rebuild\n",
    "      - Return the new loaders by calling _ex1_build_loaders()\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement set_ex1_dataloader_params() per the TODO comments\")\n",
    "\n",
    "\n",
    "# Build initial loaders\n",
    "_ = set_ex1_dataloader_params(batch_size=128, num_workers=2)\n",
    "print(\"DataLoader params:\", _ex1_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c577a",
   "metadata": {},
   "source": [
    "## Utility — Small model zoo and quick train/eval\n",
    "\n",
    "We define:\n",
    "- `get_ex1_model(name)` — small torchvision models with `num_classes=10`.\n",
    "- `ex1_train_one_epoch` and `ex1_eval_one_epoch` — quick loops with `max_steps` for short runs.\n",
    "- Both compute simple throughput metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed883fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Models ----\n",
    "def get_ex1_model(name: str):\n",
    "    name = name.lower()\n",
    "    if name == \"resnet18\":\n",
    "        m = torchvision.models.resnet18(weights=None, num_classes=10)\n",
    "    elif name == \"resnet34\":\n",
    "        m = torchvision.models.resnet34(weights=None, num_classes=10)\n",
    "    elif name in (\"mobilenet_v2\", \"mbv2\"):\n",
    "        m = torchvision.models.mobilenet_v2(weights=None, num_classes=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {name}\")\n",
    "    return m.to(device)\n",
    "\n",
    "# ---- Train / Eval helpers ----\n",
    "def ex1_train_one_epoch(model, loader, optimizer, criterion, max_steps=None):\n",
    "    \"\"\"\n",
    "    TODO: Implement a single training epoch.\n",
    "\n",
    "    Requirements:\n",
    "      - Set model to train mode.\n",
    "      - Iterate over DataLoader (respect max_steps if provided).\n",
    "      - Move inputs/labels to the global `device` with non_blocking=True.\n",
    "      - Zero grads, forward pass, compute loss, backward, optimizer step.\n",
    "      - Track total samples and total loss (sum loss * batch_size).\n",
    "      - Measure wall-clock latency (seconds) and compute throughput (samples/sec).\n",
    "      - Return a dict with:\n",
    "          {\n",
    "            \"loss\": <mean_loss_over_seen_samples>,\n",
    "            \"num_samples\": <n_seen>,\n",
    "            \"latency_s\": <epoch_time_seconds>,\n",
    "            \"throughput_samp_per_s\": <n_seen / latency_s>,\n",
    "          }\n",
    "    Notes:\n",
    "      - Assume globals: `device`, and `time` imported.\n",
    "    \"\"\"\n",
    "    # ===== TODO 1: enter train mode =====\n",
    "    # model.train()\n",
    "\n",
    "    # ===== TODO 2: init counters and start timer =====\n",
    "\n",
    "    # ===== TODO 3: iterate over loader =====\n",
    "\n",
    "    # ===== TODO 4: stop timer, compute metrics =====\n",
    "\n",
    "    # ===== TODO 5: return metrics dict =====\n",
    "\n",
    "    raise NotImplementedError(\"Complete ex1_train_one_epoch per the TODOs above.\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ex1_eval_one_epoch(model, loader, criterion, max_steps=None):\n",
    "    \"\"\"\n",
    "    TODO: Implement a single evaluation epoch.\n",
    "\n",
    "    Requirements:\n",
    "      - Set model to eval mode.\n",
    "      - Iterate over DataLoader (respect max_steps if provided).\n",
    "      - Move inputs/labels to the global `device` with non_blocking=True.\n",
    "      - Forward pass only; compute loss and accuracy (argmax over logits).\n",
    "      - Track total samples, correct predictions, and summed loss * batch_size.\n",
    "      - Measure wall-clock latency (seconds) and compute throughput (samples/sec).\n",
    "      - Return a dict with:\n",
    "          {\n",
    "            \"loss\": <mean_loss_over_seen_samples>,\n",
    "            \"acc\": <correct / n_seen>,\n",
    "            \"num_samples\": <n_seen>,\n",
    "            \"latency_s\": <eval_time_seconds>,\n",
    "            \"throughput_samp_per_s\": <n_seen / latency_s>,\n",
    "          }\n",
    "    Notes:\n",
    "      - Assume globals: `device`, and `time` imported.\n",
    "    \"\"\"\n",
    "    # ===== TODO 1: eval mode & init counters/timer =====\n",
    "\n",
    "    # ===== TODO 2: iterate over loader =====\n",
    "\n",
    "    # ===== TODO 3: finalize metrics and return =====\n",
    "    raise NotImplementedError(\"Complete ex1_eval_one_epoch per the TODOs above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01522c",
   "metadata": {},
   "source": [
    "### Quick smoke run (Task A deliverable)\n",
    "\n",
    "One short train/eval to confirm everything is wired. We cap steps so it’s fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628ac72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stats: {'loss': 4.506065475940704, 'num_samples': 2560, 'latency_s': 1.396545648574829, 'throughput_samp_per_s': 1833.0943944528221}\n",
      "Val   stats: {'loss': 621.117073059082, 'acc': 0.0984375, 'num_samples': 2560, 'latency_s': 0.40219855308532715, 'throughput_samp_per_s': 6365.0154391701435}\n"
     ]
    }
   ],
   "source": [
    "# ---- Task A: quick run ----\n",
    "loaders = set_ex1_dataloader_params(batch_size=128, num_workers=2)\n",
    "train_loader, test_loader = loaders[\"train\"], loaders[\"test\"]\n",
    "\n",
    "model = get_ex1_model(\"resnet18\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "train_stats = ex1_train_one_epoch(model, train_loader, optimizer, criterion, max_steps=20)\n",
    "val_stats   = ex1_eval_one_epoch(model, test_loader, criterion, max_steps=20)\n",
    "\n",
    "print(\"Train stats:\", train_stats)\n",
    "print(\"Val   stats:\", val_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996e1d2",
   "metadata": {},
   "source": [
    "## Task B — Add a second model and compare\n",
    "\n",
    "We compare `resnet18` vs `resnet34` (you can swap in `mobilenet_v2` if you prefer).\n",
    "Each uses the exact same pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e704ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resnet18': {'train': {'loss': 4.539602792263031,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 0.9383394718170166,\n",
       "   'throughput_samp_per_s': 2728.223715285868},\n",
       "  'val': {'loss': 15.011657333374023,\n",
       "   'acc': 0.110546875,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 0.3471341133117676,\n",
       "   'throughput_samp_per_s': 7374.67134986188}},\n",
       " 'resnet34': {'train': {'loss': 5.312578654289245,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 1.404033899307251,\n",
       "   'throughput_samp_per_s': 1823.3177997077576},\n",
       "  'val': {'loss': 349704.790625,\n",
       "   'acc': 0.1046875,\n",
       "   'num_samples': 2560,\n",
       "   'latency_s': 0.36156678199768066,\n",
       "   'throughput_samp_per_s': 7080.296441658243}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Task B: compare two models under same loaders ----\n",
    "def ex1_compare_models(model_names=(\"resnet18\", \"resnet34\"), max_steps=20):\n",
    "    \"\"\"\n",
    "    TODO: Compare multiple models on a short training/eval run.\n",
    "\n",
    "    Requirements:\n",
    "      - Loop over each name in model_names.\n",
    "      - Build a model instance with get_ex1_model(name).\n",
    "      - Construct an optimizer (SGD with lr=0.1, momentum=0.9).\n",
    "      - Call ex1_train_one_epoch(...) with train_loader, optimizer, criterion, and max_steps.\n",
    "      - Call ex1_eval_one_epoch(...) with test_loader, criterion, and max_steps.\n",
    "      - Store results in a dict keyed by model name, with subkeys \"train\" and \"val\".\n",
    "      - Return the dict at the end.\n",
    "\n",
    "    Expected return format:\n",
    "      {\n",
    "        \"resnet18\": {\"train\": {...}, \"val\": {...}},\n",
    "        \"resnet34\": {\"train\": {...}, \"val\": {...}},\n",
    "      }\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # ===== TODO 1: iterate over model_names =====\n",
    "    # for name in model_names:\n",
    "    #     # TODO 2: build model with get_ex1_model(name)\n",
    "    #\n",
    "    #     # TODO 3: define optimizer (SGD, lr=0.1, momentum=0.9)\n",
    "    #\n",
    "    #     # TODO 4: run one short training epoch\n",
    "    #\n",
    "    #     # TODO 5: run one short eval epoch\n",
    "    #\n",
    "    #     # TODO 6: store results\n",
    "\n",
    "    # ===== TODO 7: return results =====\n",
    "    # return results\n",
    "\n",
    "    raise NotImplementedError(\"Complete ex1_compare_models per the TODOs above.\")\n",
    "\n",
    "\n",
    "compare_models = ex1_compare_models(model_names=(\"resnet18\",\"resnet34\"), max_steps=20)\n",
    "compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847bf2f",
   "metadata": {},
   "source": [
    "## Task C — PyTorch Profiler → TensorBoard (top ops)\n",
    "\n",
    "We wrap a very short training loop with the profiler and export traces to TensorBoard.\n",
    "Open TensorBoard and navigate to **Profile → Operator View** to see top ops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb48122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-08-24 19:59:57 26644:26644 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-08-24 19:59:57 26644:26644 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-08-24 19:59:57 26644:26644 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.51%     529.000us         5.66%       5.827ms     145.675us       0.000us         0.00%      50.437ms       1.261ms           0 b           0 b      53.70 Mb     -72.75 Mb            40  \n",
      "                                   ConvolutionBackward0         0.25%     255.000us         4.86%       5.004ms     125.100us       0.000us         0.00%      50.236ms       1.256ms           0 b           0 b     126.45 Mb           0 b            40  \n",
      "                             aten::convolution_backward         3.03%       3.115ms         4.61%       4.749ms     118.725us      50.236ms        51.60%      50.236ms       1.256ms           0 b           0 b     126.45 Mb      41.00 Mb            40  \n",
      "void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3...         0.00%       0.000us         0.00%       0.000us       0.000us      47.360ms        48.65%      47.360ms       1.894ms           0 b           0 b           0 b           0 b            25  \n",
      "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us      14.815ms        15.22%      14.815ms       7.407ms           0 b           0 b           0 b           0 b             2  \n",
      "                                          ProfilerStep*        18.81%      19.365ms        67.02%      68.990ms      34.495ms       0.000us         0.00%      12.074ms       6.037ms           0 b           0 b           0 b     -32.29 Mb             2  \n",
      "                                           aten::conv2d         0.15%     154.000us         3.44%       3.544ms      88.600us       0.000us         0.00%       7.125ms     178.125us           0 b           0 b      51.50 Mb           0 b            40  \n",
      "                                      aten::convolution         0.34%     353.000us         3.29%       3.390ms      84.750us       0.000us         0.00%       7.125ms     178.125us           0 b           0 b      51.50 Mb           0 b            40  \n",
      "                                     aten::_convolution         0.25%     261.000us         2.95%       3.037ms      75.925us       0.000us         0.00%       7.125ms     178.125us           0 b           0 b      51.50 Mb           0 b            40  \n",
      "                                aten::cudnn_convolution         1.87%       1.927ms         2.70%       2.776ms      69.400us       7.125ms         7.32%       7.125ms     178.125us           0 b           0 b      51.50 Mb      51.50 Mb            40  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 102.944ms\n",
      "Self CUDA time total: 97.354ms\n",
      "\n",
      "Profiler traces saved to: ./runs/ex1_solution. Launch TensorBoard pointing to this folder.\n"
     ]
    }
   ],
   "source": [
    "# ---- Task C: Profiler to TensorBoard (Starter with TODOs) ----\n",
    "from torch.profiler import profile, ProfilerActivity, schedule\n",
    "\n",
    "# TODO 1: Define a log directory and reset it if it exists\n",
    "# Hints:\n",
    "#   - use log_dir = \"./runs/ex1_solution\"\n",
    "#   - if os.path.exists(log_dir): shutil.rmtree(log_dir)\n",
    "#   - create a SummaryWriter with this log_dir\n",
    "log_dir = None\n",
    "writer = None\n",
    "\n",
    "# TODO 2: Build a small model (e.g., resnet18) and optimizer (SGD)\n",
    "#   - model_prof = get_ex1_model(\"resnet18\")\n",
    "#   - opt_prof = optim.SGD(model_prof.parameters(), lr=0.1, momentum=0.9)\n",
    "model_prof = None\n",
    "opt_prof = None\n",
    "\n",
    "# TODO 3: Define a short profiler schedule to keep run quick\n",
    "#   - schedule(wait=1, warmup=1, active=2, repeat=1)\n",
    "sched = None\n",
    "\n",
    "# Helper: trace handler\n",
    "def _trace_handler(p):\n",
    "    # TODO 4: Export Chrome trace to log_dir (trace.json)\n",
    "    # Hints:\n",
    "    #   - p.export_chrome_trace(os.path.join(log_dir, \"trace.json\"))\n",
    "    # TODO 5: Print top ops (CUDA if available, else CPU)\n",
    "    # Hints:\n",
    "    #   - use p.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10)\n",
    "    #   - fall back to cpu_time_total if cuda not available\n",
    "    pass\n",
    "\n",
    "# TODO 6: Choose activities\n",
    "#   - Always include ProfilerActivity.CPU\n",
    "#   - Add ProfilerActivity.CUDA if device.type == \"cuda\"\n",
    "activities = []\n",
    "\n",
    "# TODO 7: Profile training loop\n",
    "#   - Wrap with `with profile(...) as prof:`\n",
    "#   - Include arguments:\n",
    "#       activities=activities, schedule=sched,\n",
    "#       on_trace_ready=_trace_handler,\n",
    "#       record_shapes=True, profile_memory=True, with_stack=False\n",
    "#   - Inside loop:\n",
    "#       for xb, yb in train_loader:\n",
    "#           xb, yb = xb.to(device), yb.to(device)\n",
    "#           opt_prof.zero_grad()\n",
    "#           out = model_prof(xb)\n",
    "#           loss = criterion(out, yb)\n",
    "#           loss.backward()\n",
    "#           opt_prof.step()\n",
    "#           prof.step()\n",
    "#           stop after ~20 steps\n",
    "with profile(...):\n",
    "    pass  # TODO: implement training + prof.step()\n",
    "\n",
    "# TODO 8: Flush and close the SummaryWriter\n",
    "# writer.flush()\n",
    "# writer.close()\n",
    "\n",
    "print(f\"Profiler traces saved to: {log_dir}. Launch TensorBoard pointing to this folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98999c2",
   "metadata": {},
   "source": [
    "## Task D — Ablations: Batch size & `num_workers`\n",
    "\n",
    "We sweep a few configurations and measure throughput quickly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f24dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>train_throughput</th>\n",
       "      <th>val_throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2867.734725</td>\n",
       "      <td>5682.424407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2885.691414</td>\n",
       "      <td>7082.141089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>2751.918987</td>\n",
       "      <td>9267.580045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  num_workers  train_throughput  val_throughput\n",
       "0          64            2       2867.734725     5682.424407\n",
       "1         128            2       2885.691414     7082.141089\n",
       "2         128            4       2751.918987     9267.580045"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Task D: Ablations ----\n",
    "import pandas as pd\n",
    "\n",
    "def ex1_ablate(configs=((64, 2), (128, 2), (128, 4)), max_steps=20):\n",
    "    \"\"\"\n",
    "    TODO: Run a small ablation to study how DataLoader batch size and num_workers\n",
    "    affect training/evaluation throughput.\n",
    "\n",
    "    Requirements:\n",
    "      - Iterate over each (batch_size, num_workers) pair in configs.\n",
    "      - Update dataloader params using set_ex1_dataloader_params(bs, nw).\n",
    "      - Build a resnet18 model and SGD optimizer (lr=0.1, momentum=0.9).\n",
    "      - Train briefly with ex1_train_one_epoch (max_steps).\n",
    "      - Evaluate briefly with ex1_eval_one_epoch (max_steps).\n",
    "      - Collect results (bs, nw, train throughput, val throughput) into rows.\n",
    "      - Return as a tidy pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # ===== loop over configs =====\n",
    "    for bs, nw in configs:\n",
    "    #     # TODO 2: set dataloader parameters\n",
    "    #\n",
    "    #     # TODO 3: get model (resnet18) and optimizer (SGD)\n",
    "    #\n",
    "    #     # TODO 4: run one short training epoch\n",
    "    #\n",
    "    #     # TODO 5: run one short eval epoch\n",
    "    #\n",
    "    #     # TODO 6: collect throughput results\n",
    "\n",
    "    # ===== TODO 7: return results as DataFrame =====\n",
    "\n",
    "    raise NotImplementedError(\"Complete ex1_ablate per the TODOs above.\")\n",
    "\n",
    "\n",
    "df_abl = ex1_ablate(configs=((64,2),(128,2),(128,4)), max_steps=20)\n",
    "df_abl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118e060",
   "metadata": {},
   "source": [
    "### Launch TensorBoard from VS Code (UI way)\n",
    "\n",
    "- Open the project folder in VS Code.\n",
    "\n",
    "- Press `Ctrl/Cmd + Shift + P` → run “Python: Launch TensorBoard” (or “Launch TensorBoard”).\n",
    "\n",
    "- Choose your log directory (e.g., `runs/` or `logs/`), pick a port (default `6006`).\n",
    "\n",
    "- TensorBoard opens in an editor tab (or your browser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1d4a8-eb96-4a0f-878d-c820caf27df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs/ex1_solution --host 0.0.0.0 --port 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
